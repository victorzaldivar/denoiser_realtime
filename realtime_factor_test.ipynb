{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df319871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import causal_improved_sudormrf_v3 \n",
    "import soundfile as sf\n",
    "from os.path import join as pjoin\n",
    "import time as t\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a969f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d495498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d46f11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sudormrf_causal_cpu(model_path, device):\n",
    "    # 1: declarem el model (instanciem la classe)\n",
    "    model = causal_improved_sudormrf_v3.CausalSuDORMRF(\n",
    "        in_audio_channels=1,\n",
    "        out_channels=512,\n",
    "        in_channels=256,\n",
    "        num_blocks=16,\n",
    "        upsampling_depth=5,\n",
    "        enc_kernel_size=21,\n",
    "        enc_num_basis=512,\n",
    "        num_sources=1,\n",
    "        )\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.module.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1911b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c374728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_sudormrf_causal_cpu('e39_sudo_whamr_16k_enhnoisy_augment.pt', mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0694d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now load 5s mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f5f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture, fs = sf.read('16k_mixture.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90c91822",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = torch.tensor(mixture, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a229c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = mixture[:16000*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f3fa883",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = len(mixture) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6149b083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "010d6fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307f7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78589a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test how performance degrades when using short chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8024aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = [20] #latència de 250ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d38e0199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "sisdrs = []\n",
    "chunk_sizes = []\n",
    "minitimes = []\n",
    "for chunks in tqdm.tqdm(num_chunks):\n",
    "    #try:\n",
    "    if chunks == 1:\n",
    "        mix_list = [mixture]\n",
    "    else:\n",
    "        # split into simple chunks (rectangular window and no overlap), dropping the last one\n",
    "        mix_list = torch.split(mixture, len(mixture) // chunks)#[0:-1]\n",
    "    chunk_sizes.append(len(mix_list[0]))\n",
    "    #targets_list = torch.split(targets, len(mixture) // chunks, dim=1)[0:-1]\n",
    "    # compute the audio\n",
    "    rec_sources = []\n",
    "    tic = t.time()\n",
    "    for m in mix_list:\n",
    "        tic2 = t.time()\n",
    "        rec_sources.append(model(m.unsqueeze(0).unsqueeze(1)).squeeze())\n",
    "        tac2 = t.time()\n",
    "        minitimes.append(tac2 - tic2)\n",
    "    #rec_sources = torch.cat(rec_sources, dim=1)\n",
    "    #sisdrs.append(loss(rec_sources.unsqueeze(0), targets[:, :rec_sources.shape[1]].unsqueeze(0)).item())\n",
    "    tac = t.time()\n",
    "    times.append(tac - tic)\n",
    "    '''\n",
    "    except:\n",
    "        times.append('nan')\n",
    "        #sisdrs.append('nan')\n",
    "        chunk_sizes.append('nan')\n",
    "    ''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8359b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.1876773834228516]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# necessitem 5.13 segons per processar 5s\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f600ca2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1733717918395996,\n",
       " 0.15123796463012695,\n",
       " 0.16485881805419922,\n",
       " 0.16848468780517578,\n",
       " 0.16979193687438965,\n",
       " 0.16264700889587402,\n",
       " 0.15744423866271973,\n",
       " 0.15974926948547363,\n",
       " 0.15121984481811523,\n",
       " 0.15453529357910156,\n",
       " 0.1512129306793213,\n",
       " 0.15890216827392578,\n",
       " 0.1559598445892334,\n",
       " 0.16179680824279785,\n",
       " 0.16660618782043457,\n",
       " 0.15880703926086426,\n",
       " 0.1587047576904297,\n",
       " 0.15050601959228516,\n",
       " 0.15356063842773438,\n",
       " 0.15816283226013184]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cada frame de 0.25s necessita...\n",
    "minitimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_sizes = [x*1000 / fs for x in chunk_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef100e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'times' : times, 'ms_sizes' : ms_sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68475dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mixture)/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_factor = [x/(len(mixture)/fs) for x in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(ms_sizes, times)\n",
    "plt.ylabel('Computation time [s]')\n",
    "plt.xlabel('window size [ms]')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(ms_sizes, realtime_factor)\n",
    "plt.ylabel('realtime factor')\n",
    "plt.xlabel('window size [ms]')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in my desktop, 16000samples windows should be enough. \n",
    "# in this laptop we see we'll need at least 250ms windows, which means 4000 samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "live",
   "language": "python",
   "name": "live"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
